<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Zero-Shot Adaptation at Task-Level via Coarse-to-Fine Policy Refinement and Holistic-Local Contrastive Representation</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Zero-Shot Adaptation at Task-Level via Coarse-to-Fine Policy Refinement and Holistic-Local Contrastive Representation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Zhengwei Li</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Zhenyang Lin</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Yurou Chen</a><sup>2</sup>,</span>
                    <span class="author-block">
                      <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Lu Zhang</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Zhiyong Liu</a><sup>1,2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup> The School of Artificial Intelligence,
                      University of Chinese Academy of Sciences.</span>
                    <span class="author-block"><sup>2</sup> State Key Laboratory of Multimodal Artificial Intelligence Systems,
                      Institute of Automation, Chinese Academy of Sciences.</span>
                    <span class="author-block"> IEEE Robotics and Automation Letters (RA-L)</span>
            
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span> -->
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Meta-reinforcement learning offers a mechanism for zero-shot adaptation, enabling agents to handle new tasks with parametric variation in real-world environments. However, existing methods still struggle with task-level adaptation, which demands generalization beyond simple variations within tasks, thereby limiting their practical effectiveness. This limitation stems from a failure to leverage the hierarchical characteristics inherent in task-level adaptation, resulting in inadequate task representations and constrained policy adaptation mechanisms. 
To address these challenges, we propose a <strong>C</strong>oarse-to-<strong>F</strong>ine p<strong>O</strong>licy refinement process combined with a <strong>H</strong>olistic-<strong>L</strong>ocal contrastive <strong>R</strong>epresentation (<strong>CFOHLR</strong>) method to enable effective zero-shot policy adaptation. Specifically, we utilize task language instructions as prior knowledge to select different parameterized modules as a coarse policy. This coarse policy is subsequently refined by a fine policy generated through a hypernetwork, which produces a task-aware policy based on task representations. Additionally, since task representations can influence the effectiveness of task-aware policies, we employ contrastive learning from both holistic and local perspectives to enhance these representations for more effective policy generation. Experimental results demonstrate that our method significantly improves learning efficiency and zero-shot adaptation on new tasks, outperforming previous methods on the Meta-World ML-10 and ML-45 benchmarks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper method -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title">Method</h2>
          <div class="content has-text-justified">
            <p>
              We address the challenge of task-level adaptation, which requires agents to adapt diverse tasks. To achieve this, we propose a novel meta-RL framework that combines coarse-to-fine policy refinement with holistic-local contrastive task representations to enhance learning efficiency and zero-shot adaptation. Our method leverages the hierarchical characteristics inherent in task-level adaptation to improve adaptation performance. Our framework comprises two key components: coarse-to-fine policy refinement and holistic-local contrastive task representations. The coarse-to-fine policy refinement integrates a task instruction-guided mechanism for selecting task-specific parameterized modules as the coarse policy with a hypernetwork-based task-aware policy as the fine policy. To develop robust task representations for generating effective task-aware policies, we introduce holistic-local contrastive task representations that operate at both task inter-category and intra-category levels.
            </p>
            <div class="has-text-centered">
              <img src="static/images/Framework.png" alt="Method" width="80%">
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End paper poster -->




<!-- Paper results -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title">Results</h2>
          <div class="content has-text-justified">
            <h3 class="title is-4">Experimental Setup</h3>
            <p>
              We evaluate our method using the Meta-World benchmarks, which assess agents' generalization capabilities across diverse task distributions. This benchmark suite encompasses 50 distinct robotic manipulation tasks, with each task featuring 50 parametric variants that incorporate randomized goals and initial object positions. The ML-10 benchmark comprises N<sub>train</sub>=10 training tasks and N<sub>test</sub> = 5 test tasks, while the ML-45 benchmark includes N<sub>train</sub> = 45 training tasks and N<sub>test</sub> = 5 test tasks. The benchmarks do not provide task IDs as input; instead, agents must infer task attributes through experience while maximizing their return within a meta-episode of H<sup>+</sup> = 1000 steps, consisting of n<sub>roll</sub> = 2 rollout episodes with a horizon of H = 500 steps each. To demonstrate the adaptability of our method and baseline methods to unseen tasks, the meta-trained policies were rolled out across two episodes.
            </p>
            <h3 class="title is-4">Comparison Results</h3>
            <p>&bull; To demonstrate the adaptability of our method and baseline methods to unseen tasks, the meta-trained policies were rolled out across two episodes. We report the maximum success rate averaged across six seeds, along with the corresponding returns.</p>
            <div class="has-text-centered">
              <img src="static/images/table1.png" alt="Method" width="100%">
            </div>
            <br>
            <p>
              &bull; The Learning Curves of Success Rates and Returns on Meta-World Training Tasks as shown in the following figure:
            </p>
            <div class="has-text-centered">
              <img src="static/images/Training Curve.png" alt="Method" width="80%">
            </div>
            <h3 class="title is-4">Ablation Study</h3>
            <p>
              &bull; To evaluate the key components of our method, we performed ablation studies focusing on two crucial elements: the coarse-to-fine policy refinement (CFO) and the holistic-local contrastive task representations (HLR).
            </p>
            <div class="has-text-centered">
              <img src="static/images/table2.png" alt="Method" width="100%">
            </div>
            <h3 class="title is-4">Real-World Evaluation</h3>
            <p> 
              &bull; We train CFOHLR on the Meta-World simulation suite and deploy the trained policy directly on the UR3 arm without real-world fine-tuning. Quantitatively, we evaluate 10 trials for each task, achieving an average success rate of 90% on the open-drawer task and 100% on the close-drawer task.
            </p>
            <div class="item item-video1" style="max-width: 800px; margin: 0 auto;">
              <video poster="" id="video1" autoplay controls muted loop style="width:100%; height:auto;">
                <!-- Your video file here -->
                <source src="static/videos/OpenDrawer.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video2" style="max-width: 800px; margin: 0 auto;">
              <video poster="" id="video2" autoplay controls muted loop style="width:100%; height:auto;">
                <!-- Your video file here -->
                <source src="static/videos/CloseDrawer.mp4"
                type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End paper poster -->



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Supplementary</h2>

      <iframe  src="static/pdfs/Appendix.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->




<!-- Paper conclusion -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
      <h2 class="title">Conclusion</h2>
      <div class="content has-text-justified">
        <p>
          In this study, we introduce a novel method that significantly enhances zero-shot performance in task-level adaptation within meta-RL. This improvement stems from incorporating hierarchical characteristics in both task representation and policy execution. Our approach integrates coarse-to-fine policy refinement with holistic-local contrastive task representation. Specifically, we leverage task instructions to select parameterized modules as a coarse policy, which is subsequently refined by a fine policy employing a hypernetwork to generate task-aware policies based on task representations. To develop effective task-aware policies, we implement contrastive learning at both holistic and local levels to create robust task representations.
        </p>
      </div>
      </div>
    </div>
    </div>
  </div>
</section>


<!-- Paper conclusion -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
      <h2 class="title">BibTex</h2>
      <div class="content has-text-justified">
        <p>
          <div style="border-radius: 8px; padding: 16px; border: 1px solid #e0e0e0;">
            @article{li2025zero,
              <br>title={Zero-Shot Adaptation at Task-Level via Coarse-to-Fine Policy Refinement and Holistic-Local Contrastive Representation},
              <br>author={Li, Zhengwei and Lin, Zhenyang and Chen, Yurou and Zhang, Lu and Liu, Zhiyong},
              <br>journal={IEEE Robotics and Automation Letters},
              <br>year={2025},
              <br>publisher={IEEE}
              <br>}
          </div>
        </p>
      </div>
      </div>
    </div>
    </div>
  </div>
</section>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
